<!DOCTYPE html>
<html>
<head>
    <title>Hand Tracking Test</title>

    <style>
        body {
            margin: 0;
            display: flex;
            height: 100vh;
            background: black;
            color: white;
            font-family: Arial;
        }

        .left {
            flex: 2;
            display: flex;
            justify-content: center;
            align-items: center;
            font-size: 2rem;
            text-align: center;
        }

        .right {
            flex: 1;
            display: flex;
            justify-content: center;
            align-items: center;
            border-left: 2px solid red;
        }

        .camera-wrapper {
            position: relative;
            width: 100%;
            max-width: 400px;
        }

        video {
            width: 100%;
            transform: scaleX(-1); /* mirror effect */
        }

        canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            pointer-events: none;
        }
    </style>
</head>

<body>

<div class="left" id="status">
    Show Your Hands
</div>

<div class="right">
    <div class="camera-wrapper">
        <video id="video" autoplay playsinline></video>
        <canvas id="canvas"></canvas>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

<script>

const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const statusText = document.getElementById("status");

const hands = new Hands({
    locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
});

hands.setOptions({
    maxNumHands: 2,
    modelComplexity: 1,
    minDetectionConfidence: 0.7,
    minTrackingConfidence: 0.7
});

/* Resize canvas when video loads */
video.addEventListener("loadeddata", () => {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
});

/* When MediaPipe returns results */
hands.onResults(results => {

    ctx.clearRect(0, 0, canvas.width, canvas.height);

    /* Draw video frame */
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    const count = results.multiHandLandmarks.length;

    if (count === 0) {
        statusText.innerText = "No hands detected";
    }
    else if (count === 1) {
        statusText.innerText = "1 hand detected";
    }
    else {
        statusText.innerText = "2 hands detected";
    }

    /* Draw red landmark dots */
    results.multiHandLandmarks.forEach(landmarks => {

        landmarks.forEach(point => {
            ctx.beginPath();
            ctx.arc(
                point.x * canvas.width,
                point.y * canvas.height,
                5,
                0,
                2 * Math.PI
            );
            ctx.fillStyle = "red";
            ctx.fill();
        });

    });
    if (isRightHandTechnique(results)) {
    statusText.innerText = "TECHNIQUE ACTIVATED";
    statusText.style.color = "red";
    }


});

/* Start camera */
const camera = new Camera(video, {
    onFrame: async () => {
        await hands.send({ image: video });
    },
    width: 640,
    height: 480
});

camera.start();

function isRightHandTechnique(results) {

    if (results.multiHandLandmarks.length !== 1) return false;

    const handedness = results.multiHandedness[0].label;
    if (handedness !== "Right") return false;

    const landmarks = results.multiHandLandmarks[0];

    const indexUp = landmarks[8].y < landmarks[6].y;
    const middleUp = landmarks[12].y < landmarks[10].y;
    const ringDown = landmarks[16].y > landmarks[14].y;
    const pinkyDown = landmarks[20].y > landmarks[18].y;

    return indexUp && middleUp && ringDown && pinkyDown;
}

</script>

</body>
</html>
